{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d750df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde24f8",
   "metadata": {},
   "source": [
    "# Computing Gradients\n",
    "To differentiate automaticly TF needs to remember what operations happened and in which order during the forward pass and then traverse this list of operations in reverse order in the backpropagation. <br>\n",
    "For that TF uses gradient tape to keep track of these operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e198db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function\n",
    "w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
    "b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n",
    "x = [[1., 2., 3.]]\n",
    "\n",
    "# forward pass\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x @ w + b\n",
    "    loss = tf.reduce_mean(y**2)\n",
    "\n",
    "# apply backpropagation\n",
    "[dl_dw, dl_db] = tape.gradient(loss, [w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "640882fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 4.3425727   0.26980785]\n",
      " [ 8.685145    0.5396157 ]\n",
      " [13.027718    0.80942357]], shape=(3, 2), dtype=float32)\n",
      "tf.Tensor([4.3425727  0.26980785], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(dl_dw)\n",
    "print(dl_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dda0e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.GradientTape has its persistent property set to False, meaning that after the first gradient call (tape.gradient)\n",
    "# the tape gets deleted, if persistent is set to True it won't"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b1ece",
   "metadata": {},
   "source": [
    "# Gradients with respect to a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef070689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually gradient tape gets used in combination with a Model or Layer in regards to which it would compute the gradient\n",
    "# models and subclasses aggregate their variables in model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e48cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(2, activation='relu')\n",
    "x = tf.constant([[1., 2., 3.]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # Forward pass\n",
    "    y = layer(x)\n",
    "    loss = tf.reduce_mean(y**2)\n",
    "\n",
    "# Calculate gradients with respect to every trainable variable\n",
    "grad = tape.gradient(loss, layer.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8717f353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel, shape: (3, 2)\n",
      "bias, shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "# so our trainable variables are from our layer. It's kernel and bias\n",
    "for var, g in zip(layer.trainable_variables, grad):\n",
    "    print(f'{var.name}, shape: {g.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108b3eef",
   "metadata": {},
   "source": [
    "# What the Tape watches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f18da3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# A trainable variable\n",
    "x0 = tf.Variable(3.0, name='x0')\n",
    "# Not trainable\n",
    "x1 = tf.Variable(3.0, name='x1', trainable=False)\n",
    "# Not a Variable: A variable + tensor returns a tensor.\n",
    "x2 = tf.Variable(2.0, name='x2') + 1.0\n",
    "# Not a variable\n",
    "x3 = tf.constant(3.0, name='x3')\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = (x0**2) + (x1**2) + (x2**2)\n",
    "\n",
    "grad = tape.gradient(y, [x0, x1, x2, x3])\n",
    "\n",
    "# The tape only computed a gradient for x0 since its a trainable Variable that automaticly gets watched\n",
    "# gradient tape returns None if no gradient is computed\n",
    "for g in grad:\n",
    "    print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34a2173a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# to record gradients in respect to a tensor you need to use watch\n",
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x**2\n",
    "\n",
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx.numpy())\n",
    "# and to only watch variables that should be watched set automaticly watched variables to false\n",
    "# tf.GradientTape(watch_accessed_variables=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc35af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more to gradient tape here: https://www.tensorflow.org/guide/autodiff\n",
    "# Gradients of non-scalar targets\n",
    "# Control flow (if statements)\n",
    "# common errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
